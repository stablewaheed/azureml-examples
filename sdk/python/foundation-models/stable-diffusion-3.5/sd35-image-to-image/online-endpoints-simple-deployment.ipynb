{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and score a machine learning model by using an online endpoint \n",
    "\n",
    "Learn how to use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure. You'll begin by deploying a model on your local machine to debug any errors, and then you'll deploy and test it in Azure.\n",
    "\n",
    "Managed online endpoints help to deploy your ML models in a turnkey manner. Managed online endpoints work with powerful CPU and GPU machines in Azure in a scalable, fully managed way. Managed online endpoints take care of serving, scaling, securing, and monitoring your models, freeing you from the overhead of setting up and managing the underlying infrastructure. \n",
    "\n",
    "For more information, see [What are Azure Machine Learning endpoints?](https://learn.microsoft.com/azure/machine-learning/concept-endpoints), and [Deploy an ML model with an online endpoint](https://learn.microsoft.com/azure/machine-learning/how-to-deploy-online-endpoints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* To use Azure Machine Learning, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n",
    "\n",
    "* Install and configure the [Python SDK v2](sdk/setup.sh).\n",
    "\n",
    "* You must have an Azure resource group, and you (or the service principal you use) must have Contributor access to it.\n",
    "\n",
    "* You must have an Azure Machine Learning workspace. \n",
    "\n",
    "* To deploy locally, you must install Docker Engine on your local computer. We highly recommend this option, so it's easier to debug issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docker\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.10/site-packages (from docker) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./venv/lib/python3.10/site-packages (from docker) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests>=2.26.0->docker) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests>=2.26.0->docker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests>=2.26.0->docker) (2024.8.30)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Installing collected packages: docker\n",
      "Successfully installed docker-7.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting azure-ai-ml\n",
      "  Using cached azure_ai_ml-1.22.4-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting azure-identity\n",
      "  Using cached azure_identity-1.19.0-py3-none-any.whl.metadata (80 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (6.0.2)\n",
      "Collecting msrest>=0.6.18 (from azure-ai-ml)\n",
      "  Using cached msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting azure-core>=1.23.0 (from azure-ai-ml)\n",
      "  Using cached azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting azure-mgmt-core>=1.3.0 (from azure-ai-ml)\n",
      "  Using cached azure_mgmt_core-1.5.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting marshmallow>=3.5 (from azure-ai-ml)\n",
      "  Using cached marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting jsonschema>=4.0.0 (from azure-ai-ml)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (4.67.1)\n",
      "Collecting strictyaml (from azure-ai-ml)\n",
      "  Using cached strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting colorama (from azure-ai-ml)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pyjwt (from azure-ai-ml)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting azure-storage-blob>=12.10.0 (from azure-ai-ml)\n",
      "  Using cached azure_storage_blob-12.24.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting azure-storage-file-share (from azure-ai-ml)\n",
      "  Using cached azure_storage_file_share-12.20.0-py3-none-any.whl.metadata (49 kB)\n",
      "Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml)\n",
      "  Using cached azure_storage_file_datalake-12.18.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pydash>=6.0.0 (from azure-ai-ml)\n",
      "  Using cached pydash-8.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting isodate (from azure-ai-ml)\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting azure-common>=1.1 (from azure-ai-ml)\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (4.12.2)\n",
      "Collecting opencensus-ext-azure (from azure-ai-ml)\n",
      "  Using cached opencensus_ext_azure-1.1.13-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting opencensus-ext-logging (from azure-ai-ml)\n",
      "  Using cached opencensus_ext_logging-0.1.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting cryptography>=2.5 (from azure-identity)\n",
      "  Using cached cryptography-44.0.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity)\n",
      "  Using cached msal-1.31.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity)\n",
      "  Using cached msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./venv/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in ./venv/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.17.0)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.5->azure-identity)\n",
      "  Using cached cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.0.0->azure-ai-ml)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.0.0->azure-ai-ml)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.0.0->azure-ai-ml)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.0.0->azure-ai-ml)\n",
      "  Using cached rpds_py-0.22.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.10/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.2)\n",
      "Collecting portalocker<3,>=1.4 (from msal-extensions>=1.2.0->azure-identity)\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.8.30)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.18->azure-ai-ml)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting opencensus<1.0.0,>=0.11.4 (from opencensus-ext-azure->azure-ai-ml)\n",
      "  Using cached opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: psutil>=5.6.3 in ./venv/lib/python3.10/site-packages (from opencensus-ext-azure->azure-ai-ml) (6.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in ./venv/lib/python3.10/site-packages (from strictyaml->azure-ai-ml) (2.9.0.post0)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.5->azure-identity)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Using cached opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Using cached google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2.2.3)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in ./venv/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (5.28.3)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Using cached proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached azure_ai_ml-1.22.4-py3-none-any.whl (12.3 MB)\n",
      "Using cached azure_identity-1.19.0-py3-none-any.whl (187 kB)\n",
      "Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Using cached azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
      "Using cached azure_mgmt_core-1.5.0-py3-none-any.whl (30 kB)\n",
      "Using cached azure_storage_blob-12.24.0-py3-none-any.whl (408 kB)\n",
      "Using cached azure_storage_file_datalake-12.18.0-py3-none-any.whl (258 kB)\n",
      "Using cached cryptography-44.0.0-cp39-abi3-macosx_10_9_universal2.whl (6.5 MB)\n",
      "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Using cached msal-1.31.1-py3-none-any.whl (113 kB)\n",
      "Using cached msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Using cached pydash-8.0.4-py3-none-any.whl (101 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached azure_storage_file_share-12.20.0-py3-none-any.whl (286 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached opencensus_ext_azure-1.1.13-py2.py3-none-any.whl (43 kB)\n",
      "Using cached opencensus_ext_logging-0.1.1-py2.py3-none-any.whl (4.0 kB)\n",
      "Using cached strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached rpds_py-0.22.3-cp310-cp310-macosx_11_0_arm64.whl (349 kB)\n",
      "Using cached google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Using cached proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: opencensus-context, azure-common, rpds-py, pyjwt, pydash, pycparser, pyasn1, proto-plus, portalocker, oauthlib, marshmallow, isodate, googleapis-common-protos, colorama, cachetools, attrs, strictyaml, rsa, requests-oauthlib, referencing, pyasn1-modules, cffi, azure-core, msrest, jsonschema-specifications, google-auth, cryptography, azure-mgmt-core, jsonschema, google-api-core, azure-storage-file-share, azure-storage-blob, opencensus, msal, azure-storage-file-datalake, opencensus-ext-logging, msal-extensions, azure-identity, opencensus-ext-azure, azure-ai-ml\n",
      "Successfully installed attrs-24.2.0 azure-ai-ml-1.22.4 azure-common-1.1.28 azure-core-1.32.0 azure-identity-1.19.0 azure-mgmt-core-1.5.0 azure-storage-blob-12.24.0 azure-storage-file-datalake-12.18.0 azure-storage-file-share-12.20.0 cachetools-5.5.0 cffi-1.17.1 colorama-0.4.6 cryptography-44.0.0 google-api-core-2.24.0 google-auth-2.37.0 googleapis-common-protos-1.66.0 isodate-0.7.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 marshmallow-3.23.1 msal-1.31.1 msal-extensions-1.2.0 msrest-0.7.1 oauthlib-3.2.2 opencensus-0.11.4 opencensus-context-0.1.3 opencensus-ext-azure-1.1.13 opencensus-ext-logging-0.1.1 portalocker-2.10.1 proto-plus-1.25.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycparser-2.22 pydash-8.0.4 pyjwt-2.10.1 referencing-0.35.1 requests-oauthlib-2.0.0 rpds-py-0.22.3 rsa-4.9 strictyaml-1.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: azure-ai-ml in ./venv/lib/python3.10/site-packages (1.22.4)\n",
      "Requirement already satisfied: azure-identity in ./venv/lib/python3.10/site-packages (1.19.0)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (6.0.2)\n",
      "Requirement already satisfied: msrest>=0.6.18 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\n",
      "Requirement already satisfied: azure-core>=1.23.0 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (1.32.0)\n",
      "Requirement already satisfied: azure-mgmt-core>=1.3.0 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (1.5.0)\n",
      "Requirement already satisfied: marshmallow>=3.5 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (3.23.1)\n",
      "Requirement already satisfied: jsonschema>=4.0.0 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (4.23.0)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (4.67.1)\n",
      "Requirement already satisfied: strictyaml in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (1.7.3)\n",
      "Requirement already satisfied: colorama in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\n",
      "Requirement already satisfied: pyjwt in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (2.10.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (12.24.0)\n",
      "Requirement already satisfied: azure-storage-file-share in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (12.20.0)\n",
      "Requirement already satisfied: azure-storage-file-datalake>=12.2.0 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (12.18.0)\n",
      "Requirement already satisfied: pydash>=6.0.0 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (8.0.4)\n",
      "Requirement already satisfied: isodate in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (0.7.2)\n",
      "Requirement already satisfied: azure-common>=1.1 in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (4.12.2)\n",
      "Requirement already satisfied: opencensus-ext-azure in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (1.1.13)\n",
      "Requirement already satisfied: opencensus-ext-logging in ./venv/lib/python3.10/site-packages (from azure-ai-ml) (0.1.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in ./venv/lib/python3.10/site-packages (from azure-identity) (44.0.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in ./venv/lib/python3.10/site-packages (from azure-identity) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in ./venv/lib/python3.10/site-packages (from azure-identity) (1.2.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./venv/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in ./venv/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.22.3)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.10/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.2)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in ./venv/lib/python3.10/site-packages (from msal-extensions>=1.2.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.8.30)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in ./venv/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2.0.0)\n",
      "Requirement already satisfied: opencensus<1.0.0,>=0.11.4 in ./venv/lib/python3.10/site-packages (from opencensus-ext-azure->azure-ai-ml) (0.11.4)\n",
      "Requirement already satisfied: psutil>=5.6.3 in ./venv/lib/python3.10/site-packages (from opencensus-ext-azure->azure-ai-ml) (6.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in ./venv/lib/python3.10/site-packages (from strictyaml->azure-ai-ml) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in ./venv/lib/python3.10/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in ./venv/lib/python3.10/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.24.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2.2.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./venv/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in ./venv/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (5.28.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./venv/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.25.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in ./venv/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.37.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install docker\n",
    "%pip install azure-ai-ml azure-identity\n",
    "%pip install --upgrade azure-ai-ml azure-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../jobs/configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter details of your AML workspace\n",
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace = \"<AML_WORKSPACE_NAME>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and debug locally by using local endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "* To deploy locally, [Docker Engine](https://docs.docker.com/engine/install/) must be installed.\n",
    "* Docker Engine must be running. Docker Engine typically starts when the computer starts. If it doesn't, you can [troubleshoot Docker Engine](https://docs.docker.com/config/daemon/#start-the-daemon-manually)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define endpoint and deployment\n",
    "\n",
    "## 2.1 Define the endpoint\n",
    "\n",
    "To define an endpoint, you need to specify:\n",
    "\n",
    "* Endpoint name: The name of the endpoint. It must be unique in the Azure region. For more information on the naming rules, see [managed online endpoint limits](how-to-manage-quotas.md#azure-machine-learning-managed-online-endpoints).\n",
    "* Authentication mode: The authentication method for the endpoint. Choose between key-based authentication and Azure Machine Learning token-based authentication. A key doesn't expire, but a token does expire. For more information on authenticating, see [Authenticate to an online endpoint](how-to-authenticate-online-endpoint.md).\n",
    "* Optionally, you can add a description and tags to your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an endpoint name\n",
    "endpoint_name = \"my-endpoint\"\n",
    "\n",
    "# Example way to define a random name\n",
    "import datetime\n",
    "\n",
    "endpoint_name = \"endpt-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description=\"this is a sample online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define the deployment\n",
    "\n",
    "A deployment is a set of resources required for hosting the model that does the actual inferencing. To deploy a model, you must have:\n",
    "\n",
    "- Model files (or the name and version of a model that's already registered in your workspace). In the example, we have a scikit-learn model that does regression.\n",
    "- A scoring script, that is, code that executes the model on a given input request. The scoring script receives data submitted to a deployed web service and passes it to the model. The script then executes the model and returns its response to the client. The scoring script is specific to your model and must understand the data that the model expects as input and returns as output. In this example, we have a *score.py* file.\n",
    "- An environment in which your model runs. The environment can be a Docker image with Conda dependencies or a Dockerfile.\n",
    "- Settings to specify the instance type and scaling capacity.\n",
    "\n",
    "The following table describes the key attributes of a deployment:\n",
    "\n",
    "| Attribute      | Description                                                                                                                                                                                                                                                                                                                                                                                    |\n",
    "|-----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Name           | The name of the deployment.                                                                                                                                                                                                                                                                                                                                                                    |\n",
    "| Endpoint name  | The name of the endpoint to create the deployment under.                                                                                                                                                                                                                                                                                                                                       |\n",
    "| Model          | The model to use for the deployment. This value can be either a reference to an existing versioned model in the workspace or an inline model specification.                                                                                                                                                                                                                                    |\n",
    "| Code path      | The path to the directory on the local development environment that contains all the Python source code for scoring the model. You can use nested directories and packages.                                                                                                                                                                                                                    |\n",
    "| Scoring script | The relative path to the scoring file in the source code directory. This Python code must have an `init()` function and a `run()` function. The `init()` function will be called after the model is created or updated (you can use it to cache the model in memory, for example). The `run()` function is called at every invocation of the endpoint to do the actual scoring and prediction. |\n",
    "| Environment    | The environment to host the model and code. This value can be either a reference to an existing versioned environment in the workspace or an inline environment specification.                                                                                                                                                                                                                 |\n",
    "| Instance type  | The VM size to use for the deployment. For the list of supported sizes, see [Managed online endpoints SKU list](reference-managed-online-endpoints-vm-sku-list.md).                                                                                                                                                                                                                            |\n",
    "| Instance count | The number of instances to use for the deployment. Base the value on the workload you expect. For high availability, we recommend that you set the value to at least `3`. We reserve an extra 20% for performing upgrades. For more information, see [managed online endpoint quotas](how-to-manage-quotas.md#azure-machine-learning-managed-online-endpoints).                                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/waheedbrown/workspaces/git/stable-diffusion-3.5-medium\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m Environment(\n\u001b[1;32m      3\u001b[0m     image\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcr.microsoft.com/en-us/artifact/mar/azureml/minimal-ubuntu22.04-py39-cuda11.8-gpu-inference\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m blue_deployment \u001b[38;5;241m=\u001b[39m ManagedOnlineDeployment(\n\u001b[1;32m      7\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     endpoint_name\u001b[38;5;241m=\u001b[39mendpoint_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     instance_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/entities/_assets/_artifacts/model.py:104\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, name, version, type, path, utc_time_created, flavors, description, tags, properties, stage, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_anonymous \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath:\n\u001b[1;32m    103\u001b[0m     _ignore_file \u001b[38;5;241m=\u001b[39m get_ignore_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n\u001b[0;32m--> 104\u001b[0m     _upload_hash \u001b[38;5;241m=\u001b[39m \u001b[43mget_object_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ignore_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m get_md5_string(_upload_hash)\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py:298\u001b[0m, in \u001b[0;36mget_object_hash\u001b[0;34m(path, ignore_file)\u001b[0m\n\u001b[1;32m    296\u001b[0m _hash \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39mmd5(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialize for october 2021 AML CLI version\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 298\u001b[0m     object_hash \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dir_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mislink(path):  \u001b[38;5;66;03m# ensure we're hashing the contents of the linked file\u001b[39;00m\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py:262\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    260\u001b[0m         _hash \u001b[38;5;241m=\u001b[39m _get_file_hash(path, _hash)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 262\u001b[0m         _hash \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dir_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _hash\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py:262\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    260\u001b[0m         _hash \u001b[38;5;241m=\u001b[39m _get_file_hash(path, _hash)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 262\u001b[0m         _hash \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dir_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _hash\n",
      "    \u001b[0;31m[... skipping similar frames: _get_dir_hash at line 262 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py:262\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    260\u001b[0m         _hash \u001b[38;5;241m=\u001b[39m _get_file_hash(path, _hash)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 262\u001b[0m         _hash \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dir_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _hash\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py:260\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    258\u001b[0m     path \u001b[38;5;241m=\u001b[39m _resolve_path(path)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m--> 260\u001b[0m     _hash \u001b[38;5;241m=\u001b[39m \u001b[43m_get_file_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_hash\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m    262\u001b[0m     _hash \u001b[38;5;241m=\u001b[39m _get_dir_hash(path, _hash, ignore_file)\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py:246\u001b[0m, in \u001b[0;36m_get_file_hash\u001b[0;34m(filename, _hash)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(filename), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: f\u001b[38;5;241m.\u001b[39mread(CHUNK_SIZE), \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 246\u001b[0m         \u001b[43m_hash\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _hash\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model = Model(path=\"../model-1/model/sklearn_regression_model.pkl\")\n",
    "model = Model(path=\"/Users/waheedbrown/workspaces/git/stable-diffusion-3.5-medium\")\n",
    "env = Environment(\n",
    "    #conda_file=\"../model-1/environment/conda.yaml\",\n",
    "    #image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    image=\"mcr.microsoft.com/en-us/artifact/mar/azureml/minimal-ubuntu22.04-py39-cuda11.8-gpu-inference\",\n",
    ")\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        #code=\"../model-1/onlinescoring\", scoring_script=\"score.py\"\n",
    "        code=\".\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    #instance_type=\"Standard_DS3_v2\",\n",
    "    instance_type=\"Standard_NC24ads_A100_v4\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create local endpoint and deployment\n",
    "\n",
    "## 3.1 Create local endpoint\n",
    "\n",
    "The goal of a local endpoint deployment is to validate and debug your code and configuration before you deploy to Azure. Local deployment has the following limitations:\n",
    "* Local endpoints *do not support* traffic rules, authentication, or probe settings.\n",
    "* Local endpoints support only one deployment per endpoint.\n",
    "* They support local model files only. If you want to test registered models, first download them, then use `path` in the deployment definition to refer to the parent folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local endpoint (endpt-12111831576704) .Done (0m 5s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': None, 'scoring_uri': None, 'openapi_uri': None, 'name': 'endpt-12111831576704', 'description': 'this is a sample online endpoint', 'tags': {'foo': 'bar'}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': PosixPath('/Users/waheedbrown/.azureml/inferencing/endpt-12111831576704'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x17996ea40>, 'auth_mode': 'key', 'location': None, 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Create local deployment\n",
    "\n",
    "Now, create a deployment named `blue` under the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local deployment (endpt-12111831576704 / blue) ."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_deployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblue_deployment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/core/tracing/decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:289\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    287\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    288\u001b[0m         ):\n\u001b[0;32m--> 289\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/operations/_online_deployment_operations.py:144\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, local, vscode_debug, skip_script_validation, local_enable_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m LocalDeploymentGPUNotAvailable(\n\u001b[1;32m    139\u001b[0m                 msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    140\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNvidia GPU is not available in your local system.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use nvidia-smi command to see the available GPU\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m                 )\n\u001b[1;32m    143\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_deployment_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_local_endpoint_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvscode_debug\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deployment \u001b[38;5;129;01mand\u001b[39;00m deployment\u001b[38;5;241m.\u001b[39minstance_type \u001b[38;5;129;01mand\u001b[39;00m deployment\u001b[38;5;241m.\u001b[39minstance_type\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m SmallSKUs:\n\u001b[1;32m    150\u001b[0m     module_logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m may be too small for compute resources. \u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: \u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://learn.microsoft.com/en-us/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    154\u001b[0m         deployment\u001b[38;5;241m.\u001b[39minstance_type,  \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     )\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/operations/_local_deployment_helper.py:90\u001b[0m, in \u001b[0;36m_LocalDeploymentHelper.create_or_update\u001b[0;34m(self, deployment, local_endpoint_mode, local_enable_gpu)\u001b[0m\n\u001b[1;32m     84\u001b[0m     deployment_metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(deployment\u001b[38;5;241m.\u001b[39m_to_dict())\n\u001b[1;32m     85\u001b[0m     endpoint_metadata \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     86\u001b[0m         endpoint_metadata\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m endpoint_metadata\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m _get_stubbed_endpoint_metadata(endpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(deployment\u001b[38;5;241m.\u001b[39mendpoint_name))\n\u001b[1;32m     89\u001b[0m     )\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mlocal_endpoint_polling_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_deployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moperation_message\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m / \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m) \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(endpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(deployment\u001b[38;5;241m.\u001b[39mendpoint_name), deployment_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(deployment\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=W0718\u001b[39;00m\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/_utils/_endpoint_utils.py:102\u001b[0m, in \u001b[0;36mlocal_endpoint_polling_wrapper\u001b[0;34m(func, message, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    101\u001b[0m event \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39msubmit(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 102\u001b[0m \u001b[43mpolling_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoller\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m event\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/workspaces/git/solution-engineer-demos/companies/microsoft/azure-endpoints/sd35-image-to-image/venv/lib/python3.10/site-packages/azure/ai/ml/_utils/_endpoint_utils.py:77\u001b[0m, in \u001b[0;36mpolling_wait\u001b[0;34m(poller, message, start_time, is_local, timeout)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m poller\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     76\u001b[0m         module_logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLROConfigurations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSLEEP_TIME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     poller\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(\n",
    "    deployment=blue_deployment, local=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `local=True` flag directs the SDK to deploy the endpoint in the Docker environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Verify the local deployment succeeded\n",
    "\n",
    "## 4.1 Check the status to see whether the model was deployed without error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.get(name=endpoint_name, local=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Get logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=endpoint_name, local=True, lines=50\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Invoke the local endpoint\n",
    "Invoke the endpoint to score the model by using the convenience command invoke and passing query parameters that are stored in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    #request_file=\"../model-1/sample-request.json\",\n",
    "    request_file=\"./sample-curl-request.sh\",\n",
    "    local=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Deploy your online endpoint to Azure\n",
    "Next, deploy your online endpoint to Azure.\n",
    "\n",
    "## 5.1 Create the endpoint\n",
    "Using the `endpoint` we defined earlier and the `MLClient` created earlier, we'll now create the endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Create the deployment\n",
    "\n",
    "Using the `blue_deployment` that we defined earlier and the `MLClient` we created earlier, we'll now create the deployment in the workspace. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test the endpoint with sample data\n",
    "Using the `MLClient` created earlier, we will get a handle to the endpoint. The endpoint can be invoked using the `invoke` command with the following parameters:\n",
    "- `endpoint_name` - Name of the endpoint\n",
    "- `request_file` - File with request data\n",
    "- `deployment_name` - Name of the specific deployment to test in an endpoint\n",
    "\n",
    "We will send a sample request using a [json](./model-1/sample-request.json) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the blue deployment with some sample data\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    deployment_name=\"blue\",\n",
    "    #request_file=\"../model-1/sample-request.json\",\n",
    "    request_file=\"./sample-curl-request.sh\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Managing endpoints and deployments\n",
    "\n",
    "## 7.1 Get details of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=endpoint_name)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Get the logs for the new deployment\n",
    "Get the logs for the green deployment and verify as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=endpoint_name, lines=50\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Delete the endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_delete(name=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
